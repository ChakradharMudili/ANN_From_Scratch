{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5G_sLp35LAJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid_act(x, der=False):\n",
        "    import numpy as np\n",
        "    \n",
        "    if (der==True) : #derivative of the sigmoid\n",
        "        f = 1/(1+ np.exp(- x))*(1-1/(1+ np.exp(- x)))\n",
        "    else : # sigmoid\n",
        "        f = 1/(1+ np.exp(- x))\n",
        "    \n",
        "    return f\n",
        "\n",
        "# We may employ the Rectifier Linear Unit (ReLU)\n",
        "def ReLU_act(x, der=False):\n",
        "    import numpy as np\n",
        "    \n",
        "    if (der == True): # the derivative of the ReLU is the Heaviside Theta\n",
        "        f = np.heaviside(x, 1)\n",
        "    else :\n",
        "        f = np.maximum(x, 0)\n",
        "    \n",
        "    return f\n",
        "# Now we are ready to define the perceptron; \n",
        "# it eats a np.array (that may be a list of features )\n",
        "def perceptron(X, act='Sigmoid'): \n",
        "    import numpy as np\n",
        "    \n",
        "    shapes = X.shape # Pick the number of (rows, columns)!\n",
        "    n= shapes[0]+shapes[1]\n",
        "    # Generating random weights and bias\n",
        "    w = 2*np.random.random(shapes) - 0.5 # We want w to be between -1 and 1\n",
        "    b = np.random.random(1)\n",
        "    \n",
        "    # Initialize the function\n",
        "    f = b[0]\n",
        "    for i in range(0, X.shape[0]-1) : # run over column elements\n",
        "        for j in range(0, X.shape[1]-1) : # run over rows elements\n",
        "            f += w[i, j]*X[i,j]/n\n",
        "    # Pass it to the activation function and return it as an output\n",
        "    if act == 'Sigmoid':\n",
        "        output = sigmoid_act(f)\n",
        "    else :\n",
        "        output = ReLU_act(f)\n",
        "        \n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN_train(X_train, Y_train, p=4, q=4, eta=0.0015):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    # 0: Random initialize the relevant data \n",
        "    w1 = 2*np.random.rand(p , X_train.shape[1]) - 0.5 # Layer 1\n",
        "    b1 = np.random.rand(p)\n",
        "\n",
        "    w2 = 2*np.random.rand(q , p) - 0.5  # Layer 2\n",
        "    b2 = np.random.rand(q)\n",
        "\n",
        "    wOut = 2*np.random.rand(q) - 0.5   # Output Layer\n",
        "    bOut = np.random.rand(1)\n",
        "\n",
        "    mu = []\n",
        "    vec_y = []\n",
        "\n",
        "    # Start looping over the passengers, i.e. over I.\n",
        "\n",
        "    for I in range(0, X_train.shape[0]-1): #loop in all the passengers:\n",
        "    \n",
        "        # 1: input the data \n",
        "        x = X_train[I]\n",
        "    \n",
        "        # 2: Start the algorithm\n",
        "    \n",
        "        # 2.1: Feed forward\n",
        "        z1 = ReLU_act(np.dot(w1, x) + b1) # output layer 1 \n",
        "        z2 = ReLU_act(np.dot(w2, z1) + b2) # output layer 2\n",
        "        y = sigmoid_act(np.dot(wOut, z2) + bOut) # Output of the Output layer\n",
        "    \n",
        "        #2.2: Compute the output layer's error\n",
        "        delta_Out = 2 * (y-Y_train[I]) * sigmoid_act(y, der=True)\n",
        "    \n",
        "        #2.3: Backpropagate\n",
        "        delta_2 = delta_Out * wOut * ReLU_act(z2, der=True) # Second Layer Error\n",
        "        delta_1 = np.dot(delta_2, w2) * ReLU_act(z1, der=True) # First Layer Error\n",
        "    \n",
        "        # 3: Gradient descent \n",
        "        wOut = wOut - eta*delta_Out*z2  # Outer Layer\n",
        "        bOut = bOut - eta*delta_Out\n",
        "    \n",
        "        w2 = w2 - eta*np.kron(delta_2, z1).reshape(q,p) # Hidden Layer 2\n",
        "        b2 = b2 -  eta*delta_2\n",
        "    \n",
        "        w1 = w1 - eta*np.kron(delta_1, x).reshape(p, x.shape[0])\n",
        "        b1 = b1 - eta*delta_1\n",
        "    \n",
        "        # 4. Computation of the loss function\n",
        "        mu.append((y-Y_train[I])**2)\n",
        "        vec_y.append(y)\n",
        "    return w1, b1, w2, b2, wOut, bOut, mu"
      ],
      "metadata": {
        "id": "Bc__AjNu-vb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN_pred(X_test, w1, b1, w2, b2, wOut, bOut, mu):\n",
        "    import numpy as np\n",
        "    \n",
        "    pred = []\n",
        "    \n",
        "    for I in range(0, X_test.shape[0]): #loop in all the passengers\n",
        "        # 1: input the data \n",
        "        x = X_test[I]\n",
        "        \n",
        "        # 2.1: Feed forward\n",
        "        z1 = ReLU_act(np.dot(w1, x) + b1) # output layer 1 \n",
        "        z2 = ReLU_act(np.dot(w2, z1) + b2) # output layer 2\n",
        "        y = sigmoid_act(np.dot(wOut, z2) + bOut)  # Output of the Output layer\n",
        "        \n",
        "        # Append the prediction;\n",
        "        # We now need a binary classifier; we this apply an Heaviside Theta and we set to 0.5 the threshold\n",
        "        # if y < 0.5 the output is zero, otherwise is 1\n",
        "        pred.append( np.heaviside(y - 0.5, 1)[0] )\n",
        "    \n",
        "    \n",
        "    return np.array(pred);"
      ],
      "metadata": {
        "id": "3XVqi-LWa5vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN_train(X_train, Y_train, p=4, q=4, eta=0.0015):\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    # 0: Random initialize the relevant data \n",
        "    w1 = 2*np.random.rand(p , X_train.shape[1]) - 0.5 # Layer 1\n",
        "    b1 = np.random.rand(p)\n",
        "\n",
        "    w2 = 2*np.random.rand(q , p) - 0.5  # Layer 2\n",
        "    b2 = np.random.rand(q)\n",
        "\n",
        "    wOut = 2*np.random.rand(q) - 0.5   # Output Layer\n",
        "    bOut = np.random.rand(1)\n",
        "\n",
        "    mu = []\n",
        "    vec_y = []\n",
        "\n",
        "    # Start looping over the passengers, i.e. over I.\n",
        "\n",
        "    for I in range(0, X_train.shape[0]-1): #loop in all the passengers:\n",
        "    \n",
        "        # 1: input the data \n",
        "        x = X_train[I]\n",
        "    \n",
        "        # 2: Start the algorithm\n",
        "    \n",
        "        # 2.1: Feed forward\n",
        "        z1 = ReLU_act(np.dot(w1, x) + b1) # output layer 1 \n",
        "        z2 = ReLU_act(np.dot(w2, z1) + b2) # output layer 2\n",
        "        y = sigmoid_act(np.dot(wOut, z2) + bOut) # Output of the Output layer\n",
        "    \n",
        "        #2.2: Compute the output layer's error\n",
        "        delta_Out = 2 * (y-Y_train[I]) * sigmoid_act(y, der=True)\n",
        "    \n",
        "        #2.3: Backpropagate\n",
        "        delta_2 = delta_Out * wOut * ReLU_act(z2, der=True) # Second Layer Error\n",
        "        delta_1 = np.dot(delta_2, w2) * ReLU_act(z1, der=True) # First Layer Error\n",
        "    \n",
        "        # 3: Gradient descent \n",
        "        wOut = wOut - eta*delta_Out*z2  # Outer Layer\n",
        "        bOut = bOut - eta*delta_Out\n",
        "    \n",
        "        w2 = w2 - eta*np.kron(delta_2, z1).reshape(q,p) # Hidden Layer 2\n",
        "        b2 = b2 -  eta*delta_2\n",
        "    \n",
        "        w1 = w1 - eta*np.kron(delta_1, x).reshape(p, x.shape[0])\n",
        "        b1 = b1 - eta*delta_1\n",
        "    \n",
        "        # 4. Computation of the loss function\n",
        "        mu.append((y-Y_train[I])**2)\n",
        "        vec_y.append(y)\n",
        "        \n",
        "    return w1, b1, w2, b2, wOut, bOut, mu"
      ],
      "metadata": {
        "id": "2RnthcxHZAnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "with open('/content/Training.txt','r') as file:\n",
        "  \n",
        "  for line in file:\n",
        "    sub = []\n",
        "    for word in line.split():\n",
        "      sub.append(word)\n",
        "\n",
        "    if(len(sub)!=0):\n",
        "      temp=[float(sub[0]),float(sub[1])]\n",
        "\n",
        "      X_train.append(temp)\n",
        "      \n",
        "      y_train.append(int(sub[2]))\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "LCFKI8-LVNnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "with open('/content/Testing.txt','r') as file:\n",
        "  \n",
        "  for line in file:\n",
        "    sub = []\n",
        "    for word in line.split():\n",
        "      sub.append(word)\n",
        "\n",
        "    if(len(sub)!=0):\n",
        "      temp=[float(sub[0]),float(sub[1])]\n",
        "\n",
        "      X_test.append(temp)\n",
        "      \n",
        "      y_test.append(int(sub[2]))\n",
        "\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "KV4yTNzNVaSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, b1, w2, b2, wOut, bOut, mu = ANN_train(X_train, y_train, p=8, q=4, eta=0.0015)"
      ],
      "metadata": {
        "id": "TG8ANCOpaI8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w1, b1, w2, b2, wOut, bOut, mu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-QMUQciaKtU",
        "outputId": "f0f3c274-c30e-4855-ef05-552f57c6831e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.84724783  0.05611099]\n",
            " [ 0.00462777  0.91010094]\n",
            " [ 0.88843369  1.23503967]\n",
            " [ 0.92198817  1.29284837]\n",
            " [ 1.45153146  0.26957682]\n",
            " [-0.11938345 -0.30985145]\n",
            " [ 1.21371109  1.03272426]\n",
            " [ 0.07057676 -0.58989197]] [0.49608299 0.97083835 0.38405346 0.7535418  0.44007656 0.78006684\n",
            " 0.60766867 0.83492115] [[ 0.964618    0.57762696  0.11931377 -0.16909287  0.12942227  1.14960028\n",
            "   0.10663768  1.17807357]\n",
            " [-0.45005078 -0.61379689  0.81138151  0.22454062 -0.1302891   0.48707089\n",
            "   1.0737248   0.72526847]\n",
            " [ 0.16890886 -0.2382491  -0.37784474 -0.18531927  0.66561438  0.65603818\n",
            "   1.02918563  0.2457604 ]\n",
            " [-0.3907511   0.61466202  0.60243963  1.34344439  0.74639636  1.2947221\n",
            "  -0.06126932  0.93591965]] [0.78453512 0.49012534 0.54902291 0.80587427] [ 0.4384229   0.3709902  -0.36785065 -0.27190281] [0.58719804] [array([4.]), array([8.21012272e-17]), array([0.]), array([7.82934421e-17]), array([4.]), array([3.99999997]), array([3.99999964]), array([1.99120436e-15]), array([3.99999924]), array([4.]), array([0.]), array([4.]), array([9.10335128e-12]), array([3.99999993]), array([8.11809629e-13]), array([3.14569699e-15]), array([1.87995987e-14]), array([2.28294888e-15]), array([0.]), array([3.99979059]), array([4.]), array([7.63028706e-15]), array([8.69719148e-29]), array([7.54255844e-10]), array([0.]), array([9.68452287e-12]), array([2.07943925e-09]), array([3.99999536]), array([1.05768518e-18]), array([4.]), array([4.]), array([4.]), array([3.99999997]), array([0.]), array([2.67761657e-11]), array([9.177183e-10]), array([3.99489132]), array([4.08174673e-13]), array([2.09169122e-08]), array([9.00437425e-13]), array([4.]), array([3.99996878]), array([1.58788168e-13]), array([3.99971013]), array([4.37754136e-20]), array([5.52648481e-09]), array([3.96348032]), array([4.43734259e-31]), array([1.04068783e-18]), array([7.48328462e-12]), array([4.]), array([4.]), array([3.98142148]), array([4.]), array([7.46210834e-20]), array([3.99959034]), array([4.]), array([3.82149467]), array([8.46349633e-05]), array([3.99834543]), array([1.19359919e-07]), array([3.99708569]), array([3.99328892]), array([3.99999762]), array([1.54116361e-06]), array([3.99955356]), array([3.99993635]), array([9.84554019e-05]), array([0.00110141]), array([2.25907453e-05]), array([0.00039023]), array([3.98449654]), array([3.97084244]), array([1.44283241e-05]), array([3.57166215]), array([3.80753181]), array([3.95017502]), array([3.87127888]), array([0.03960979])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = ANN_pred(X_test, w1, b1, w2, b2, wOut, bOut, mu)"
      ],
      "metadata": {
        "id": "TdIT1HMFbCwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(predictions)):\n",
        "  print(y_test[i], predictions[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bnu_eQ6bD1c",
        "outputId": "0ed8461c-bfaf-44c8-f068-c7cef28d6ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "-1 0.0\n",
            "-1 0.0\n",
            "-1 1.0\n",
            "-1 1.0\n",
            "-1 0.0\n",
            "-1 1.0\n",
            "-1 0.0\n",
            "-1 1.0\n",
            "-1 1.0\n",
            "-1 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXwJfz5iigTZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}